#!/usr/bin/env python
from __future__ import print_function
import roslib
import sys
import rospy
import numpy as np
import datetime
import time
from dse_msgs.msg import PoseMarkers
from std_msgs.msg import Float64MultiArray
from std_msgs.msg import MultiArrayLayout
from std_msgs.msg import MultiArrayDimension
from dse_msgs.msg import InfFilterPartials
from dse_msgs.msg import InfFilterResults
from scipy.spatial.transform import Rotation as R

from dse_lib import *

roslib.load_manifest('dse_simulation')

class information_filter:

    # Set up initial variables
    # Pass in the ID of this agent
    def __init__(self, my_id):

        # Define publishers and subscribers
        self.pose_sub = rospy.Subscriber("/dse/pose_markers", PoseMarkers, self.measurement_callback)
        self.results_sub = rospy.Subscriber("/dse/inf/results", InfFilterResults, self.results_callback)
        self.inf_pub = rospy.Publisher("/dse/inf/partial", InfFilterPartials, queue_size=10)

        # Define static variables
        self.my_id = my_id
        self.dim_obs = 3
        self.dim_state = 6
        self.dt = 0.1
        self.t_last = rospy.get_time()
        self.euler_order = 'zyx'

        # Create information variables
        self.inf_P = []
        self.inf_x = []
        #self.inf_Y = []
        #self.inf_y = []
        self.inf_I = []
        self.inf_i = []
        #self.inf_id_list = []
        self.inf_id_obs = []
        self.inf_id_comm = []
        self.inf_id_list = [self.my_id]
        self.inf_Y = 10000 * np.eye(self.dim_state, dtype=np.float64)
        self.inf_y = 0.01 * np.transpose(1 * np.arange(1, self.dim_state+1, dtype=np.float64))[:, None]
        self.z_movavg = []
        self.z_movavg_a = 0.1

    # When the direct estimator or consensus returns the combined information variables
    def results_callback(self, data):
        self.inf_id_list = np.array(data.ids)
        self.inf_Y = multi_array_2d_output(data.inf_matrix)
        self.inf_y = multi_array_2d_output(data.inf_vector)

    # When the camera sends a measurement
    def measurement_callback(self, data):

        # Compute the actual dt
        self.dt = rospy.get_time() - self.t_last
        self.t_last = rospy.get_time()

        # Grab the tag poses from the camera
        observed_poses = data.pose_array.poses
        observed_ids = data.ids
        n = 1 + len(observed_ids)

        # update local values from the last time step
        Y_11 = self.inf_Y
        y_11 = self.inf_y
        x_11 = np.linalg.inv(Y_11).dot(y_11)
        P_11 = np.linalg.inv(Y_11)
        id_list = self.inf_id_list

        # If we find an ID that isn't currently known, add it
        for id in observed_ids:
            if not np.isin(id, id_list):
                id_list = np.concatenate((id_list, [id]))
                dim = len(id_list) * self.dim_state

                Y_11_tmp = 10000 * np.eye(dim)
                Y_11_tmp[0:np.shape(Y_11)[0], 0:np.shape(Y_11)[0]] = Y_11
                Y_11 = Y_11_tmp

                y_11_tmp = 0.01 * np.arange(1, dim+1)[:, None]
                y_11_tmp[0:np.shape(y_11)[0]] = y_11
                y_11 = y_11_tmp

                x_11 = np.linalg.inv(Y_11).dot(y_11)
                P_11 = np.linalg.inv(Y_11)

        # Define the sizes of variables
        print("Agent " + str(self.my_id) + "'s id list is: " + str(id_list))
        n_stored = len(id_list)
        n_obs = len(observed_ids)
        F_0 = np.zeros((n_stored * self.dim_state, n_stored * self.dim_state))
        Q_0 = np.zeros((n_stored * self.dim_state, n_stored * self.dim_state))
        R_0 = 0.001 * np.eye(n_obs * self.dim_obs)
        H_0 = np.zeros((n_obs * self.dim_obs, n_stored * self.dim_state))
        z_0 = np.zeros((n_obs * self.dim_obs, 1))

        # Fill in H and Z
        for i in range(len(observed_ids)):
            id = observed_ids[i]
            index = np.where(id_list == id)[0][0]
            obs_index = np.where(id_list == self.my_id)[0][0]

            i_low = self.dim_obs * i
            i_high = i_low + self.dim_obs

            z_pos = np.array([observed_poses[i].position.x, observed_poses[i].position.y])

            quat = [1, 2, 3, 4]
            quat[0] = observed_poses[i].orientation.x
            quat[1] = observed_poses[i].orientation.y
            quat[2] = observed_poses[i].orientation.z
            quat[3] = observed_poses[i].orientation.w
            r = R.from_quat(quat)
            z_eul = r.as_euler(self.euler_order)
            z_eul = [z_eul[0]]
            print(np.concatenate((z_pos, z_eul))[:, None])

            dist = np.linalg.norm(z_pos)
            R_0[i_low:i_high, i_low:i_high] = 1 * aruco_R_from_range_3D(dist)
            print('aruco range error estimate: ' + str(aruco_R_from_range_3D(dist)))
            # H_0[i_low:i_high, :] = self.h_camera(x_11, obs_index, index)
            z_0[i_low:i_high] = np.concatenate((z_pos, z_eul))[:, None]
            H_0[i_low:i_high, :] = self.h_camera_good(x_11, z_0[i_low:i_high], obs_index, index)

        # if np.shape(self.z_movavg) == np.shape(z_0):
        #     self.z_movavg = z_0 * self.z_movavg_a + self.z_movavg * (self.z_movavg_a - 1)
        # else:
        #     print('new movavg')
        #     self.z_movavg = z_0
        # self.z_0 = self.z_movavg

        # Fill in Q and F (Different for waypoint vs. robot)
        for i in range(len(id_list)):
            if id_list[i] == 0:
                i_low = self.dim_state * i
                i_high = i_low + self.dim_state
                Q_0[i_low:i_high, i_low:i_high] = 1 * self.q_distance(self.dt, x_11, i)
                # F_0[i_low:i_high, i_low:i_high] = self.f_unicycle_2d(self.dt, x_11, i)
                F_0[i_low:i_high, i_low:i_high] = self.f_eye(self.dt, x_11, i)
            else:
                i_low = self.dim_state * i
                i_high = i_low + self.dim_state
                Q_0[i_low:i_high, i_low:i_high] = 1 * self.q_distance(self.dt, x_11, i)
                # F_0[i_low:i_high, i_low:i_high] = self.f_unicycle_2d(self.dt, x_11, i)
                F_0[i_low:i_high, i_low:i_high] = self.f_unicycle_2d(self.dt, x_11, i)

        # Compute the information filter steps
        M_0 = np.transpose(np.linalg.inv(F_0)).dot(Y_11.dot(np.linalg.inv(F_0)))
        C_0 = M_0.dot(np.linalg.inv(M_0 + np.linalg.inv(Q_0)))
        L_0 = np.eye(np.shape(C_0)[0]) - C_0
        Y_01 = L_0.dot(M_0.dot(np.transpose(L_0))) + C_0.dot(np.linalg.inv(Q_0).dot(np.transpose(C_0)))
        y_01 = L_0.dot(np.transpose(np.linalg.inv(F_0)).dot(y_11))
        Y_00 = Y_01 + np.transpose(H_0).dot(np.linalg.inv(R_0).dot(H_0))
        y_00 = y_01 + np.transpose(H_0).dot(np.linalg.inv(R_0).dot(z_0))

        # Compute the Kalman filter steps (For comparison and math checking)
        x_01 = F_0.dot(x_11)
        P_01 = F_0.dot(P_11.dot(np.transpose(F_0))) + Q_0
        y = z_0 - H_0.dot(x_01)
        S = H_0.dot(P_01.dot(np.transpose(H_0))) + R_0
        K = P_01.dot(np.transpose(H_0).dot(np.linalg.inv(S)))
        x_00 = x_01 + K.dot(y)
        P_00 = (np.eye(np.shape(K)[0]) - K.dot(H_0).dot(P_01))

        # Compare information filter and kalman filter outputs
        x_inf = np.linalg.inv(Y_00).dot(y_00)
        print('state: ' + str(x_inf))
        P_inf = np.linalg.inv(Y_00)
        P_kal = F_0.dot(np.linalg.inv(Y_11).dot((np.transpose(F_0)))) + Q_0
        P_inf = np.linalg.inv(Y_01)

        # Store the consensus variables
        inf_Y = Y_01
        inf_y = y_01
        inf_I = np.transpose(H_0).dot(np.linalg.inv(R_0).dot(H_0))
        inf_i = np.transpose(H_0).dot(np.linalg.inv(R_0).dot(z_0))
        # print('Information vector: ' + str(inf_Y))
        # print('Observation vector: ' + str(inf_I))
        inf_id_list = id_list
        inf_id_obs = observed_ids

        # Write the consensus variables to the publisher
        inf_partial = InfFilterPartials()
        inf_partial.sender_id = self.my_id
        inf_partial.ids = inf_id_list
        inf_partial.inf_matrix_prior = multi_array_2d_input(inf_Y, inf_partial.inf_matrix_prior)
        inf_partial.inf_vector_prior = multi_array_2d_input(inf_y, inf_partial.inf_vector_prior)
        inf_partial.obs_matrix = multi_array_2d_input(inf_I, inf_partial.obs_matrix)
        inf_partial.obs_vector = multi_array_2d_input(inf_i, inf_partial.obs_vector)
        self.inf_pub.publish(inf_partial)

    # Helper functions
    def state_from_id(self, x, id_list, id):
        index = np.where(id_list == id)[0][0]
        i_low = self.dim_state * index
        i_high = i_low + self.dim_state
        return x[i_low:i_high]

    def cov_from_id(self, P, id_list, id):
        index = np.where(id_list == id)[0][0]
        i_low = self.dim_state * index
        i_high = i_low + self.dim_state
        return P[i_low:i_high, i_low:i_high]

    # Define measurement jacobian for camera
    def h_camera_good(self, x, z, agent1, agent2):
        agent1_row_min = self.dim_state * agent1
        agent1_row_max = agent1_row_min + self.dim_obs
        agent2_row_min = self.dim_state * agent2
        agent2_row_max = agent2_row_min + self.dim_obs

        x1 = x[agent1_row_min:agent1_row_max]
        # t1 = x1[0:2]
        # R1 = theta_2_rotm(x1[2, 0])
        #
        x2 = x[agent2_row_min:agent2_row_max]
        # t2 = x2[0:2]
        # R2 = theta_2_rotm(x2[2, 0])

        # print(z)
        # print(R1, R2, t1, t2)
        # zt = (np.transpose(R1).dot(t2) - np.transpose(R1).dot(t1))[:, 0]
        # zR = np.transpose(R1).dot(R2)
        # zr = R.from_dcm(zR)
        # zr = zr.as_euler(self.euler_order)
        # z_calc = np.concatenate((zt, zr))[:, None]

        n_states = np.shape(x)[0]
        H = np.zeros((self.dim_obs, n_states))
        # H[:, agent1_row_min:agent1_row_max] = np.multiply(np.eye(self.dim_obs), z_calc/x1)
        Jacobian = np.array(dual_relative_obs_jacobian_3D(x1, x2))
        H[:, agent1_row_min:agent1_row_max] = Jacobian[:, 0:3]
        H[:, agent2_row_min:agent2_row_max] = Jacobian[:, 3:6]
        print(H.dot(x))
        print('\n\n')
        return H

    # Define motion jacobian for unicycle robot
    def f_unicycle_2d(self, dt, x, agent1):
        agent1_row_min = self.dim_state * agent1
        agent1_row_max = agent1_row_min + self.dim_state

        x1 = x[agent1_row_min:agent1_row_max]

        F = np.eye(self.dim_state)
        w = x1[5]

        if w == 0:
            F[0, 3] = dt
            F[0, 4] = 0
            F[1, 3] = 0
            F[1, 4] = dt

            F[3, 3] = 1
            F[3, 4] = 0
            F[4, 3] = 0
            F[4, 4] = 1
        else:
            F[0, 3] = np.sin(w*dt) / w
            F[0, 4] = -(1 - np.cos(w*dt)) / w
            F[1, 3] = (1 - np.cos(w*dt)) / w
            F[1, 4] = np.sin(w*dt) / w

            F[3, 3] = np.cos(w*dt)
            F[3, 4] = -np.sin(w*dt)
            F[4, 3] = np.sin(w*dt)
            F[4, 4] = np.cos(w*dt)

        F[2, 5] = dt
        return F

    # Define stationary jacobian for waypoints
    def f_eye(self, dt, x, agent1):
        F = np.eye(self.dim_state)
        return F

    # Define motion model covariance (distnace-based)
    def q_distance(self, dt, x, agent1):
        i_low = self.dim_state * agent1
        i_high = i_low + self.dim_state

        Q_pos = (dt * (np.linalg.norm(x[i_low+3:i_low+5]) + 0.001) * 0.05) ** 2
        Q_theta = (dt * (np.linalg.norm(x[i_low+5]) + 0.001) * 0.05) ** 2
        print('Q_pos: ' + str(Q_pos) + ' and Q_theta: ' + str(Q_theta))
        Q = 1 * np.eye(self.dim_state)
        Q[3:5, 3:5] = 0.000001 / (dt ** 2) * np.eye(2)
        Q[5, 5] = 0.000001 / (dt ** 2)
        if Q_pos > 0:
            Q[0:2, 0:2] = Q_pos * np.eye(2)
        if Q_theta > 0:
            Q[2, 2] = Q_theta
        return Q

    # Define motion model covariance (static)
    def q_const(self, dt, x, agent1):
        Q = 0.000001 * np.eye(self.dim_state)
        return Q


def main(args):
    rospy.init_node('information_filter_node', anonymous=True)
    il = information_filter(1)
    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")


if __name__ == '__main__':
    main(sys.argv)
